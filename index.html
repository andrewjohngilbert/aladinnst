<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="Representation learning aims to discover individual salient features of a domain in a compact and descriptive form that strongly identifies the unique characteristics of a given sample respective to its domain. Existing works in visual style representation literature have tried to disentangle style from content during training explicitly.">
  <meta property="og:title" content="Aladin-nst: Self-supervised disentangled representation learning of artistic style through neural style transfer"/>
  <meta property="og:description" content="Representation learning aims to discover individual salient features of a domain in a compact and descriptive form that strongly identifies the unique characteristics of a given sample respective to its domain. Existing works in visual style representation literature have tried to disentangle style from content during training explicitly."/>
  <meta property="og:url" content="https://andrewjohngilbert.github.io/aladinnst/"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="assets/aladinnst_teaser.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="Aladin-nst: Self-supervised disentangled representation learning of artistic style through neural style transfer">
  <meta name="twitter:description" content="Representation learning aims to discover individual salient features of a domain in a compact and descriptive form that strongly identifies the unique characteristics of a given sample respective to its domain. Existing works in visual style representation literature have tried to disentangle style from content during training explicitly.">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="assets/aladinnst_teaser.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Aladin-nst: Self-supervised disentangled representation learning of artistic style through neural style transfer</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon-32x32.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Aladin-nst: Self-supervised disentangled representation learning of artistic style through neural style transfer</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://danruta.co.uk/" target="_blank">Dan Ruta</a><sup>[1]</sup>,</span>
                <span class="author-block">
                  <a href="https://www.linkedin.com/in/gemmacanettarres/" target="_blank">Gemma Canet Tarres</a><sup>[1]</sup>,</span>
                  <span class="author-block">
                    <a href="https://www.surrey.ac.uk/people/alexander-black" target="_blank">Alexander Black,</a><sup>[1]</sup>,</span>
                  <span class="author-block">
                    <a href="https://andrewjohngilbert.github.io/" target="_blank">Andrew Gilbert</a><sup>[1]</sup>,</span>
                  <span class="author-block">
                    <a href="http://personal.ee.surrey.ac.uk/Personal/J.Collomosse/" target="_blank">John Collomosse</a><sup>[1,2]</sup>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">University of Surrey<sup>[1]</sup>, Adobe Resarch<sup>[2]</sup><br><a href="https://eccv2024.ecva.net/" target="_blank">The European Conference of Computer Vision 2024</a> <a href="https://visarts.eu/index.php" target="_blank">Vision for Art (VISART VII) Workshop</a></span>
                

                
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://andrewjohngilbert.github.io/aladinnst/assets/ALADIN-NST_Self-supervised_disentangled_representation_learning_of_artistic_Paper.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                  <span class="link-block">
                      <a href="assets/aladinnst_poster.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Poster</span>
                    </a>
                  </span>
 
                  <!-- Github link -->
              <!--    <span class="link-block">
                    <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
              -->

                
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Model Image -->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="assets/aladinnst_teaser.png">
      <h2 class="subtitle has-text-centered">
        (Left) Example style groups from the BAM-FG
dataset. The images in each group are style consistent, but they are also semantically consistent. For example, the top left style group has a consistent weathered paper style but is also consistent in the subject matter of character design. The top right has consistent pastel style but is consistently interiors. The bottom left is consistent moody vignette dark photography style, but all images are of landscapes. Bottom right vector art images all contain faces. (Right) Example synthetic style consistent images, as used in our work (via NeAT). The left-most images in each style group are the reference style image. The BAM-FG data (left) shows style consistency at the cost of entanglement with semantic consistency, unlike the synthetic data (right).       
</h2>
    </div>
  </div>
</section>
<!-- Model Image -->



<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Representation learning aims to discover individual salient features of a domain in a compact and descriptive form that strongly identifies the unique characteristics of a given sample respective to its domain. Existing works in visual style representation literature have tried to disentangle style from content during training explicitly. A complete separation between these has yet to be fully achieved. Our paper aims to learn a representation of visual artistic style more strongly disentangled from the semantic content depicted in an image. We use Neural Style Transfer (NST) to measure and drive the learning signal and achieve state-of-the-art representation learning on explicitly disentangled metrics. We show that strongly addressing the disentanglement of style and content leads to large gains in style-specific metrics, encoding far less semantic information and achieving state-of-the-art accuracy in downstream
multimodal applications.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Model Image -->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="assets/aladinnst_model.png">
      <h2 class="subtitle has-text-centered">
        Visualization of our NST-driven style representation learning method. We show a training iteration with batch size 6, with 6 content images and 3 style images (in our experiments, we use much larger batch sizes but use 6 here for clarity). The content images are stylized with a pre-trained and frozen Neural Style Transfer method using two copies of the 3 style images. We extract a style embedding using layer-wise global moment statistics and the logits from a more localized vision transformer.
      </h2>
    </div>
  </div>
</section>
<!-- Model Image -->

<!-- Results Image -->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="assets/aladin-nst_results.png">
      <h2 class="subtitle has-text-centered">
        Style-based image retrieval comparison between our method variants and previous literature.
      </h2>
    </div>
  </div>
</section>
<!-- Results Image -->

<!-- Paper poster -->

  <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="assets/aladinnst_poster.pdf" width="100%" height="800">
          </iframe>
        
      </div>
    </div>
  </section>
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@inproceedings{Ruta:adadinnst:ECCVWS:2024,
        AUTHOR = Ruta, Dan and Tarres, Gemma Canet and Black, Alexander and  Gilbert Andrew and Collomosse, John",
        TITLE = "Aladin-nst: Self-supervised disentangled representation learning of artistic style through neural style transfer",
        BOOKTITLE = "European Conference of Computer Vision 2024, Vision for Art (VISART VII) Workshop, 2024",",
        YEAR = "2023",
        }</code></pre>
    </div>
</section>
<!--End BibTex citation -->



  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
